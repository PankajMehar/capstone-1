{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest on Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration</th>\n",
       "      <th>energy</th>\n",
       "      <th>featured</th>\n",
       "      <th>followers</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>...</th>\n",
       "      <th>p4_mode</th>\n",
       "      <th>p4_popularity</th>\n",
       "      <th>p4_tempo</th>\n",
       "      <th>p4_time_signature</th>\n",
       "      <th>p4_valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>total_tracks</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1325</td>\n",
       "      <td>0.6995</td>\n",
       "      <td>217744.5</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>False</td>\n",
       "      <td>14284402</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>-5.0260</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.230769</td>\n",
       "      <td>110.9910</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>79.120000</td>\n",
       "      <td>102.2015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>220976.5</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>False</td>\n",
       "      <td>6061263</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>-7.6295</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.153846</td>\n",
       "      <td>121.5470</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>72.420000</td>\n",
       "      <td>142.0510</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.3110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1334</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>226361.5</td>\n",
       "      <td>0.6060</td>\n",
       "      <td>True</td>\n",
       "      <td>2954185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>-5.6395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>92.9790</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3930</td>\n",
       "      <td>65.660000</td>\n",
       "      <td>127.4455</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>214781.0</td>\n",
       "      <td>0.8185</td>\n",
       "      <td>False</td>\n",
       "      <td>2586720</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>-5.1860</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.307692</td>\n",
       "      <td>100.0430</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3790</td>\n",
       "      <td>62.460000</td>\n",
       "      <td>123.4825</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.6320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.5530</td>\n",
       "      <td>216173.0</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>False</td>\n",
       "      <td>2462696</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>-11.5270</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.150000</td>\n",
       "      <td>117.9865</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>54.320513</td>\n",
       "      <td>124.8580</td>\n",
       "      <td>4.0</td>\n",
       "      <td>78</td>\n",
       "      <td>0.3130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration  energy featured  followers  \\\n",
       "0        0.1325        0.6995  217744.5  0.5920    False   14284402   \n",
       "1        0.0318        0.7675  220976.5  0.5255    False    6061263   \n",
       "2        0.1334        0.7275  226361.5  0.6060     True    2954185   \n",
       "3        0.0254        0.5820  214781.0  0.8185    False    2586720   \n",
       "4        0.8790        0.5530  216173.0  0.3170    False    2462696   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness   ...     p4_mode  p4_popularity  \\\n",
       "0          0.000005  3.0    0.1130   -5.0260   ...         1.0      75.230769   \n",
       "1          0.000032  3.0    0.1070   -7.6295   ...         1.0      68.153846   \n",
       "2          0.000000  4.5    0.1035   -5.6395   ...         0.0      55.000000   \n",
       "3          0.000008  8.0    0.1665   -5.1860   ...         1.0      58.307692   \n",
       "4          0.003090  3.0    0.1100  -11.5270   ...         1.0      51.150000   \n",
       "\n",
       "   p4_tempo  p4_time_signature  p4_valence  popularity     tempo  \\\n",
       "0  110.9910                4.0      0.4180   79.120000  102.2015   \n",
       "1  121.5470                4.0      0.3520   72.420000  142.0510   \n",
       "2   92.9790                4.0      0.3930   65.660000  127.4455   \n",
       "3  100.0430                4.0      0.3790   62.460000  123.4825   \n",
       "4  117.9865                4.0      0.3495   54.320513  124.8580   \n",
       "\n",
       "   time_signature  total_tracks  valence  \n",
       "0             4.0            50   0.4910  \n",
       "1             4.0            59   0.3110  \n",
       "2             4.0            50   0.4855  \n",
       "3             4.0            50   0.6320  \n",
       "4             4.0            78   0.3130  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_data = pd.read_csv('playlist_data_with_sequencing_4.8.17.csv')\n",
    "api_data = api_data.dropna()\n",
    "del api_data['Unnamed: 0']\n",
    "del api_data['names']\n",
    "del api_data['playlist_id']\n",
    "api_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api_data['featured'] = api_data.featured.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api_data2 = api_data.copy()\n",
    "api_data2['featured'] = api_data2.featured.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api_data2 = api_data.copy()\n",
    "api_data2['featured'] = api_data2.featured.astype(int)\n",
    "feature_list = ['acousticness',\n",
    " 'danceability',\n",
    " 'duration',\n",
    " 'energy',\n",
    " 'instrumentalness',\n",
    " 'key',\n",
    " 'liveness',\n",
    " 'loudness',\n",
    " 'mean_num_markets',\n",
    " 'mode',\n",
    " 'p1_acousticness',\n",
    " 'p1_danceability',\n",
    " 'p1_duration',\n",
    " 'p1_energy',\n",
    " 'p1_instrumentalness',\n",
    " 'p1_key',\n",
    " 'p1_liveness',\n",
    " 'p1_loudness',\n",
    " 'p1_mean_num_markets',\n",
    " 'p1_mode',\n",
    " 'p1_popularity',\n",
    " 'p1_tempo',\n",
    " 'p1_time_signature',\n",
    " 'p1_valence',\n",
    " 'p2_acousticness',\n",
    " 'p2_danceability',\n",
    " 'p2_duration',\n",
    " 'p2_energy',\n",
    " 'p2_instrumentalness',\n",
    " 'p2_key',\n",
    " 'p2_liveness',\n",
    " 'p2_loudness',\n",
    " 'p2_mean_num_markets',\n",
    " 'p2_mode',\n",
    " 'p2_popularity',\n",
    " 'p2_tempo',\n",
    " 'p2_time_signature',\n",
    " 'p2_valence',\n",
    " 'p3_acousticness',\n",
    " 'p3_danceability',\n",
    " 'p3_duration',\n",
    " 'p3_energy',\n",
    " 'p3_instrumentalness',\n",
    " 'p3_key',\n",
    " 'p3_liveness',\n",
    " 'p3_loudness',\n",
    " 'p3_mean_num_markets',\n",
    " 'p3_mode',\n",
    " 'p3_popularity',\n",
    " 'p3_tempo',\n",
    " 'p3_time_signature',\n",
    " 'p3_valence',\n",
    " 'p4_acousticness',\n",
    " 'p4_danceability',\n",
    " 'p4_duration',\n",
    " 'p4_energy',\n",
    " 'p4_instrumentalness',\n",
    " 'p4_key',\n",
    " 'p4_liveness',\n",
    " 'p4_loudness',\n",
    " 'p4_mean_num_markets',\n",
    " 'p4_mode',\n",
    " 'p4_popularity',\n",
    " 'p4_tempo',\n",
    " 'p4_time_signature',\n",
    " 'p4_valence',\n",
    " 'popularity',\n",
    " 'tempo',\n",
    " 'total_tracks',\n",
    " 'valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.qcut(api_data[\"followers\"], 5,labels=range(1,6))\n",
    "api_data['followers'] = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rfc = RFC(n_estimators = 100)\n",
    "y = api_data['followers']\n",
    "X = api_data.drop(['followers'],axis=1)\n",
    "#rfc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarabboud1/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for row in X.iterrows():\n",
    "    preds.append(int(rfc.predict(row[1].reshape(1,-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def misclass_rate(pred, y):\n",
    "    incorr = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] != y[i]:\n",
    "            incorr += 1\n",
    "    return float(incorr)/float(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030826140567200987"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass_rate(preds, list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarabboud1/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/omarabboud1/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "for feature in feature_list:\n",
    "    try:\n",
    "        ser, bins = pd.qcut(X_train[feature], 5, retbins = True, labels=range(1,6))\n",
    "        bins[0] = -100000000\n",
    "        bins[5] = 100000000\n",
    "        X_train[feature] = ser\n",
    "        X_test[feature] = np.digitize(X_test[feature],bins)\n",
    "    except:\n",
    "        'error'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.00000000e+08   3.57600000e+02   1.61660000e+03   1.14074000e+04\n",
      "   1.38580600e+05   1.00000000e+08]\n"
     ]
    }
   ],
   "source": [
    "ser, bins = pd.qcut(y_train, 5, retbins = True, labels=range(1,6))\n",
    "bins[0] = -100000000\n",
    "bins[5] = 100000000\n",
    "print bins\n",
    "y_train = np.digitize(y_train, bins)\n",
    "y_test = np.digitize(y_test, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 227, 2: 227, 3: 227, 4: 227, 5: 227})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 89, 2: 92, 3: 110, 4: 103, 5: 93})"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(round(np.sqrt(len(X_train.iloc[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighting(y):\n",
    "\n",
    "    counter = Counter(y)\n",
    "    maximum = max(counter.values())\n",
    "    return {genre: float(maximum / count) for genre, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = weighting()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True,\n",
       "            class_weight={1: 1.0, 2: 1.0, 3: 1.0, 4: 100.0, 5: 100.0},\n",
       "            criterion='gini', max_depth=None, max_features=8,\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RFC(oob_score = True, max_features = int(round(np.sqrt(len(X_train.iloc[0])))), \\\n",
    "          class_weight={1: 1.0, 2: 1.0, 3: 1.0, 4: 100.0, 5: 100.0})\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.1,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = GBC(min_weight_fraction_leaf=0.1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RFC()\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_preds = []\n",
    "for row in X_train:\n",
    "    tr_preds.append(int(rfc.predict(row.reshape(1,-1))))\n",
    "    \n",
    "te_preds = []\n",
    "for row in X_test:\n",
    "    te_preds.append(int(rfc.predict(row.reshape(1,-1)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0105726872247\n",
      "0.681724845996\n"
     ]
    }
   ],
   "source": [
    "print misclass_rate(tr_preds, list(y_train))\n",
    "print misclass_rate(te_preds, list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[226,   1,   0,   0,   0],\n",
       "       [  2, 222,   0,   0,   3],\n",
       "       [  0,   3, 224,   0,   0],\n",
       "       [  1,   1,   0, 225,   0],\n",
       "       [  0,   1,   0,   0, 226]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(list(y_train), tr_preds,labels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46, 16, 12,  9,  6],\n",
       "       [27, 16, 19, 15, 15],\n",
       "       [28, 18, 26, 24, 14],\n",
       "       [24, 27, 19, 19, 14],\n",
       "       [ 8, 18,  5, 14, 48]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(list(y_test), te_preds,labels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-14e56e3ec760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tree.dot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/omarabboud1/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/tree/export.pyc\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"impurity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;31m# If required, draw leaf nodes at same depth as each other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "tree.export_graphviz(rfc,out_file='tree.dot')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline random forest model classifies training observations with >99% accuracy and testing observations with 39% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=29, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RFC(n_estimators = 100, max_depth = 29)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00184162062615\n",
      "0.611940298507\n"
     ]
    }
   ],
   "source": [
    "tr_preds = []\n",
    "for row in X_train.iterrows():\n",
    "    tr_preds.append(int(rfc.predict(row[1].reshape(1,-1))))\n",
    "    \n",
    "te_preds = []\n",
    "for row in X_test.iterrows():\n",
    "    te_preds.append(int(rfc.predict(row[1].reshape(1,-1)))) \n",
    "    \n",
    "print misclass_rate(tr_preds, list(y_train))\n",
    "print misclass_rate(te_preds, list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([estimator.tree_.max_depth for estimator in rfc.estimators_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarabboud1/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:9: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/omarabboud1/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:13: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "for i in [1,5,10,20,30,50,70,100]:\n",
    "    rfc = RFC(n_estimators = i)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    tr_preds = []\n",
    "    for row in X_train.iterrows():\n",
    "        tr_preds.append(int(rfc.predict(row[1].reshape(1,-1))))\n",
    "\n",
    "    te_preds = []\n",
    "    for row in X_test.iterrows():\n",
    "        te_preds.append(int(rfc.predict(row[1].reshape(1,-1)))) \n",
    "\n",
    "    train_errors.append(misclass_rate(tr_preds, list(y_train)))\n",
    "    test_errors.append(misclass_rate(te_preds, list(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.274009</td>\n",
       "      <td>0.698152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.071366</td>\n",
       "      <td>0.714579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.665298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.626283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.628337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test\n",
       "0  0.274009  0.698152\n",
       "1  0.071366  0.714579\n",
       "2  0.013216  0.665298\n",
       "3  0.003524  0.626283\n",
       "4  0.002643  0.628337"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = pd.DataFrame([train_errors,test_errors]).T\n",
    "errors.columns = ['Train','Test']\n",
    "errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarabboud1/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:9: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/omarabboud1/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:13: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "for i in [1,4,8,15,20,25,30]:\n",
    "    rfc = RFC(n_estimators = 100, max_depth = i)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    tr_preds = []\n",
    "    for row in X_train.iterrows():\n",
    "        tr_preds.append(int(rfc.predict(row[1].reshape(1,-1))))\n",
    "\n",
    "    te_preds = []\n",
    "    for row in X_test.iterrows():\n",
    "        te_preds.append(int(rfc.predict(row[1].reshape(1,-1)))) \n",
    "\n",
    "    train_errors.append(misclass_rate(tr_preds, list(y_train)))\n",
    "    test_errors.append(misclass_rate(te_preds, list(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639648</td>\n",
       "      <td>0.648871</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.469604</td>\n",
       "      <td>0.609856</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069604</td>\n",
       "      <td>0.583162</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.589322</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.620123</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test  Depth\n",
       "0  0.639648  0.648871    1.0\n",
       "1  0.469604  0.609856    4.0\n",
       "2  0.069604  0.583162    8.0\n",
       "3  0.002643  0.589322   15.0\n",
       "4  0.002643  0.620123   20.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlist = [1,4,8,15,20,25,30]\n",
    "errors = pd.DataFrame([train_errors,test_errors,tlist]).T\n",
    "errors.columns = ['Train','Test','Depth']\n",
    "errors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAHjCAYAAAA6x4aXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRV2SpEpY1CVJqsQr1IyIQ+9AlTkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1177309d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.linspace(1,len([1,5,10,20,30,50,70,100]),len([1,5,10,20,30,50,70,100]))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(tlist, train_errors, color = \"#3F883E\", linewidth = 4, label=\"Train\")\n",
    "plt.plot(tlist, test_errors, color = \"#7e7e7e\",linewidth=4, label=\"Test\")\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Misclassification Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Leaf Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 1\n",
      "Finished 5\n",
      "Finished 10\n",
      "Finished 20\n",
      "Finished 30\n",
      "Finished 40\n",
      "Finished 50\n",
      "Finished 60\n",
      "Finished 70\n",
      "Finished 80\n",
      "Finished 90\n",
      "Finished 100\n",
      "Finished 200\n",
      "Finished 500\n"
     ]
    }
   ],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "leafs = [1,5,10,20,30,40,50,60,70,80,90,100,200,500]\n",
    "for l in leafs:\n",
    "    rfc = RFC(n_estimators = 100, min_samples_leaf = l)\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    tr_preds = []\n",
    "    for row in X_train.iterrows():\n",
    "        tr_preds.append(int(rfc.predict(row[1].reshape(1,-1))))\n",
    "\n",
    "    te_preds = []\n",
    "    for row in X_test.iterrows():\n",
    "        te_preds.append(int(rfc.predict(row[1].reshape(1,-1)))) \n",
    "\n",
    "    train_errors.append(misclass_rate(tr_preds, list(y_train)))\n",
    "    test_errors.append(misclass_rate(te_preds, list(y_test)))\n",
    "    print 'Finished ' + str(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.613806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046041</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.199816</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.385820</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.466851</td>\n",
       "      <td>0.600746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train      Test\n",
       "0  0.001842  0.613806\n",
       "1  0.046041  0.597015\n",
       "2  0.199816  0.597015\n",
       "3  0.385820  0.597015\n",
       "4  0.466851  0.600746"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_2 = pd.DataFrame([train_errors,test_errors]).T\n",
    "errors_2.columns = ['Train','Test']\n",
    "errors_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAHuCAYAAABtbi5KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1178e7450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(1,len(leafs),len(leafs))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(x, train_errors, color = \"red\", label=\"Train\")\n",
    "plt.plot(x, test_errors, color = \"blue\", label=\"Test\")\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Misclassification Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'varImp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-00a2fa9683cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvarImp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'varImp' is not defined"
     ]
    }
   ],
   "source": [
    "varImp(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Class label 1 not present.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-307-b68d713851d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtr_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    472\u001b[0m                         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                     expanded_class_weight = compute_sample_weight(class_weight,\n\u001b[0;32m--> 474\u001b[0;31m                                                                   y_original)\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.pyc\u001b[0m in \u001b[0;36mcompute_sample_weight\u001b[0;34m(class_weight, y, indices)\u001b[0m\n\u001b[1;32m    166\u001b[0m             weight_k = compute_class_weight(class_weight_k,\n\u001b[1;32m    167\u001b[0m                                             \u001b[0mclasses_full\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                             y_full)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mweight_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.pyc\u001b[0m in \u001b[0;36mcompute_class_weight\u001b[0;34m(class_weight, classes, y)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class label %d not present.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Class label 1 not present."
     ]
    }
   ],
   "source": [
    "rfc = RFC(n_estimators = 100, class_weight={1:0.1,2:0.15,3:0.6,4:0.8,5:0.8})\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "tr_preds = []\n",
    "for row in X_train.iterrows():\n",
    "    tr_preds.append(int(rfc.predict(row[1].reshape(1,-1))))\n",
    "    \n",
    "te_preds = []\n",
    "for row in X_test.iterrows():\n",
    "    te_preds.append(int(rfc.predict(row[1].reshape(1,-1)))) \n",
    "    \n",
    "print misclass_rate(tr_preds, list(y_train))\n",
    "print misclass_rate(te_preds, list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03,  0.69,  0.2 ,  0.07,  0.01]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.predict_proba(X_train.iloc[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = api_data['followers']\n",
    "X = api_data.drop(['followers'],axis=1)\n",
    "X = X.drop(['featured'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "ser2, bins2 = pd.qcut(y_train, 5, retbins = True, labels = range(1,6))\n",
    "y_train = pd.cut(y_train, bins=bins2,labels=range(1,6),include_lowest=True)\n",
    "y_test = pd.cut(y_test, bins=bins2,labels=range(1,6),include_lowest=True)\n",
    "for feat in feature_list:\n",
    "    try:\n",
    "        ser, bins = pd.qcut(X_train[feat], 5,retbins = True, labels=range(1,6))\n",
    "        bins[0] = -100000000\n",
    "        bins[5] = 100000000\n",
    "        a = pd.cut(X_train[feat], bins=bins,labels=range(1,6),include_lowest=True)\n",
    "        b = pd.cut(X_test[feat], bins=bins,labels=range(1,6),include_lowest=True)\n",
    "        if a.isnull().values.any() != True and b.isnull().values.any() != True:\n",
    "            X_train[feat] = a\n",
    "            X_test[feat] = b\n",
    "    except:\n",
    "        'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration</th>\n",
       "      <th>energy</th>\n",
       "      <th>featured</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mean_num_markets</th>\n",
       "      <th>...</th>\n",
       "      <th>p4_mode</th>\n",
       "      <th>p4_popularity</th>\n",
       "      <th>p4_tempo</th>\n",
       "      <th>p4_time_signature</th>\n",
       "      <th>p4_valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>total_tracks</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness danceability duration energy  featured  instrumentalness  \\\n",
       "163             5            3        1      1         0          0.000000   \n",
       "1152            4            4        2      2         0          0.000465   \n",
       "1626            4            2        1      3         0          0.000107   \n",
       "326             5            1        5      1         0          0.878000   \n",
       "1676            5            2        4      1         0          0.000017   \n",
       "\n",
       "     key liveness loudness mean_num_markets   ...    p4_mode p4_popularity  \\\n",
       "163    2        3        2                3   ...        1.0             1   \n",
       "1152   4        2        3                4   ...        0.5             4   \n",
       "1626   4        5        3                5   ...        1.0             4   \n",
       "326    3        2        1                5   ...        1.0             1   \n",
       "1676   2        3        2                2   ...        1.0             1   \n",
       "\n",
       "     p4_tempo p4_time_signature p4_valence  popularity tempo time_signature  \\\n",
       "163         4               4.0          5           1     4            4.0   \n",
       "1152        2               4.0          3           4     4            4.0   \n",
       "1626        1               4.0          3           4     2            4.0   \n",
       "326         1               4.0          1           1     1            4.0   \n",
       "1676        4               4.0          1           1     1            4.0   \n",
       "\n",
       "     total_tracks valence  \n",
       "163             3       5  \n",
       "1152            2       1  \n",
       "1626            1       4  \n",
       "326             3       1  \n",
       "1676            1       1  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['featured'] = X_train['featured'].astype(int)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration</th>\n",
       "      <th>energy</th>\n",
       "      <th>featured</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mean_num_markets</th>\n",
       "      <th>...</th>\n",
       "      <th>p4_mode</th>\n",
       "      <th>p4_popularity</th>\n",
       "      <th>p4_tempo</th>\n",
       "      <th>p4_time_signature</th>\n",
       "      <th>p4_valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>total_tracks</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00440</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00175</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness danceability duration energy  featured  instrumentalness  \\\n",
       "1208            4            3        4      2         0           0.00440   \n",
       "791             1            2        3      5         0           0.00000   \n",
       "991             2            2        3      3         0           0.00175   \n",
       "1052            5            4        5      1         0           0.00000   \n",
       "1159            2            4        2      5         0           0.00000   \n",
       "\n",
       "     key liveness loudness mean_num_markets   ...    p4_mode p4_popularity  \\\n",
       "1208   5        2        2                1   ...        1.0             3   \n",
       "791    1        5        5                1   ...        0.0             2   \n",
       "991    4        2        3                2   ...        1.0             2   \n",
       "1052   2        4        1                5   ...        1.0             1   \n",
       "1159   2        1        5                4   ...        1.0             3   \n",
       "\n",
       "     p4_tempo p4_time_signature p4_valence  popularity tempo time_signature  \\\n",
       "1208        4               4.0          1           2     1            4.0   \n",
       "791         2               4.0          2           2     5            4.0   \n",
       "991         4               4.0          3           2     5            4.0   \n",
       "1052        1               3.0          2           1     2            4.0   \n",
       "1159        3               4.0          5           2     4            4.0   \n",
       "\n",
       "     total_tracks valence  \n",
       "1208            1       1  \n",
       "791             1       2  \n",
       "991             4       3  \n",
       "1052            5       1  \n",
       "1159            1       5  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['featured'] = X_test['featured'].astype(int)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   45000.    203467.    219133.5   233440.    256143.   3107826. ]\n",
      "181\n"
     ]
    }
   ],
   "source": [
    "ser, bins = pd.qcut(X_train['duration'], 5, retbins = True, labels=range(1,6))\n",
    "print bins\n",
    "for ix, val in enumerate(pd.cut(X_test['duration'], bins = bins, labels = range(1,6)).isnull()):\n",
    "    if val == True:\n",
    "        print ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.50000000e+04,   2.03467000e+05,   2.19133500e+05,\n",
       "         2.33440000e+05,   2.56143000e+05,   1.00000000e+09])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins[0] = -100000000\n",
    "bins[5] = 100000000\n",
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Episode 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e457dcf2aa2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "rfc = RFC(n_estimators = 100, max_depth = 29)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.615671641791\n"
     ]
    }
   ],
   "source": [
    "tr_preds = []\n",
    "for row in X_train.iterrows():\n",
    "    tr_preds.append(int(rfc.predict(row[1].reshape(1,-1))))\n",
    "    \n",
    "te_preds = []\n",
    "for row in X_test.iterrows():\n",
    "    te_preds.append(int(rfc.predict(row[1].reshape(1,-1)))) \n",
    "    \n",
    "print misclass_rate(tr_preds, list(y_train))\n",
    "print misclass_rate(te_preds, list(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song Querying Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import sys\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(client_id='df846cfd28e745178054587b3484f91c',                                                client_secret='e3d39fc92a954e028ff1490288f3fe5c')\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "    \n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "        \n",
    "    return out\n",
    "\n",
    "def gen_score(list_of_tracks):\n",
    "            \n",
    "    parts = chunks(list_of_tracks,4)\n",
    "                    \n",
    "    p1 = parts[0]\n",
    "    p2 = parts[1]\n",
    "    p3 = parts[2]\n",
    "    p4 = parts[3]\n",
    "    \n",
    "    t_popularities = []\n",
    "    t_num_markets = []\n",
    "                \n",
    "    for track in list_of_tracks:\n",
    "        listing = sp.track(track)\n",
    "        t_popularities.append(listing['popularity'])\n",
    "        t_num_markets.append(len(listing['available_markets']))\n",
    "                                        \n",
    "    t_pop = np.mean(t_popularities)\n",
    "    t_av_num_markets = np.mean(t_num_markets)\n",
    "\n",
    "    t_features = sp.audio_features(tracks = list_of_tracks)\n",
    "    feat_len = len(list_of_tracks)\n",
    "    t_feature_matrix = np.empty((feat_len,12))\n",
    "    for ix, song in enumerate(t_features):\n",
    "  \n",
    "        t_feature_matrix[ix][0] = song['acousticness']\n",
    "        t_feature_matrix[ix][1] = song['danceability']\n",
    "        t_feature_matrix[ix][2] = song['energy']\n",
    "        t_feature_matrix[ix][3] = song['instrumentalness']\n",
    "        t_feature_matrix[ix][4] = song['key']\n",
    "        t_feature_matrix[ix][5] = song['liveness']\n",
    "        t_feature_matrix[ix][6] = song['loudness']\n",
    "        t_feature_matrix[ix][7] = song['mode']\n",
    "        t_feature_matrix[ix][8] = song['tempo']\n",
    "        t_feature_matrix[ix][9] = song['time_signature']\n",
    "        t_feature_matrix[ix][10] = song['valence']\n",
    "        t_feature_matrix[ix][11] = song['duration_ms']\n",
    "                            \n",
    "    t_feature_median = np.percentile(t_feature_matrix,50,axis=0)\n",
    "                    # Part 1\n",
    "                    \n",
    "    p1_popularities = []\n",
    "    p1_num_markets = []\n",
    "                    \n",
    "    for track in p1:\n",
    "        listing = sp.track(track)\n",
    "        p1_popularities.append(listing['popularity'])\n",
    "        p1_num_markets.append(len(listing['available_markets']))\n",
    "    \n",
    "    p1_pop = np.mean(p1_popularities)\n",
    "    p1_av_num_markets = np.mean(p1_num_markets)\n",
    "    \n",
    "    p1_features = sp.audio_features(tracks = p1)\n",
    "    p1_len = len(p1)\n",
    "    p1_feature_matrix = np.empty((p1_len,12))\n",
    "                    \n",
    "    for ix, song in enumerate(p1_features):\n",
    "        p1_feature_matrix[ix][0] = song['acousticness']\n",
    "        p1_feature_matrix[ix][1] = song['danceability']\n",
    "        p1_feature_matrix[ix][2] = song['energy']\n",
    "        p1_feature_matrix[ix][3] = song['instrumentalness']\n",
    "        p1_feature_matrix[ix][4] = song['key']\n",
    "        p1_feature_matrix[ix][5] = song['liveness']\n",
    "        p1_feature_matrix[ix][6] = song['loudness']\n",
    "        p1_feature_matrix[ix][7] = song['mode']\n",
    "        p1_feature_matrix[ix][8] = song['tempo']\n",
    "        p1_feature_matrix[ix][9] = song['time_signature']\n",
    "        p1_feature_matrix[ix][10] = song['valence']\n",
    "        p1_feature_matrix[ix][11] = song['duration_ms']\n",
    "                        \n",
    "    p1_feature_median = np.percentile(p1_feature_matrix,50,axis=0)\n",
    "                    # Part 2\n",
    "                    \n",
    "    p2_popularities = []\n",
    "    p2_num_markets = []\n",
    "                    \n",
    "    for track in p2:\n",
    "        listing = sp.track(track)\n",
    "        p2_popularities.append(listing['popularity'])\n",
    "        p2_num_markets.append(len(listing['available_markets']))\n",
    "    \n",
    "    p2_pop = np.mean(p2_popularities)\n",
    "    p2_av_num_markets = np.mean(p2_num_markets)\n",
    "    \n",
    "    p2_features = sp.audio_features(tracks = p2)\n",
    "    p2_len = len(p2)\n",
    "    p2_feature_matrix = np.empty((p2_len,12))\n",
    "                    \n",
    "    for ix, song in enumerate(p2_features):\n",
    "        p2_feature_matrix[ix][0] = song['acousticness']\n",
    "        p2_feature_matrix[ix][1] = song['danceability']\n",
    "        p2_feature_matrix[ix][2] = song['energy']\n",
    "        p2_feature_matrix[ix][3] = song['instrumentalness']\n",
    "        p2_feature_matrix[ix][4] = song['key']\n",
    "        p2_feature_matrix[ix][5] = song['liveness']\n",
    "        p2_feature_matrix[ix][6] = song['loudness']\n",
    "        p2_feature_matrix[ix][7] = song['mode']\n",
    "        p2_feature_matrix[ix][8] = song['tempo']\n",
    "        p2_feature_matrix[ix][9] = song['time_signature']\n",
    "        p2_feature_matrix[ix][10] = song['valence']\n",
    "        p2_feature_matrix[ix][11] = song['duration_ms']\n",
    "                        \n",
    "    p2_feature_median = np.percentile(p2_feature_matrix,50,axis=0)\n",
    "    \n",
    "                        # Part 3\n",
    "                    \n",
    "    p3_popularities = []\n",
    "    p3_num_markets = []\n",
    "                  \n",
    "    for track in p3:\n",
    "        listing = sp.track(track)\n",
    "        p3_popularities.append(listing['popularity'])\n",
    "        p3_num_markets.append(len(listing['available_markets']))\n",
    "    \n",
    "    p3_pop = np.mean(p3_popularities)\n",
    "    p3_av_num_markets = np.mean(p3_num_markets)\n",
    "    \n",
    "    p3_features = sp.audio_features(tracks = p3)\n",
    "    p3_len = len(p3)\n",
    "    p3_feature_matrix = np.empty((p3_len,12))\n",
    "                    \n",
    "    for ix, song in enumerate(p3_features):\n",
    "        p3_feature_matrix[ix][0] = song['acousticness']\n",
    "        p3_feature_matrix[ix][1] = song['danceability']\n",
    "        p3_feature_matrix[ix][2] = song['energy']\n",
    "        p3_feature_matrix[ix][3] = song['instrumentalness']\n",
    "        p3_feature_matrix[ix][4] = song['key']\n",
    "        p3_feature_matrix[ix][5] = song['liveness']\n",
    "        p3_feature_matrix[ix][6] = song['loudness']\n",
    "        p3_feature_matrix[ix][7] = song['mode']\n",
    "        p3_feature_matrix[ix][8] = song['tempo']\n",
    "        p3_feature_matrix[ix][9] = song['time_signature']\n",
    "        p3_feature_matrix[ix][10] = song['valence']\n",
    "        p3_feature_matrix[ix][11] = song['duration_ms']\n",
    "                        \n",
    "    p3_feature_median = np.percentile(p3_feature_matrix,50,axis=0)\n",
    "    \n",
    "                        # Part 4\n",
    "                    \n",
    "    p4_popularities = []\n",
    "    p4_num_markets = []\n",
    "                    \n",
    "    for track in p4:\n",
    "        listing = sp.track(track)\n",
    "        p4_popularities.append(listing['popularity'])\n",
    "        p4_num_markets.append(len(listing['available_markets']))\n",
    "    \n",
    "    p4_pop = np.mean(p4_popularities)\n",
    "    p4_av_num_markets = np.mean(p4_num_markets)\n",
    "    \n",
    "    p4_features = sp.audio_features(tracks = p4)\n",
    "    p4_len = len(p4)\n",
    "    p4_feature_matrix = np.empty((p4_len,12))\n",
    "                    \n",
    "    for ix, song in enumerate(p4_features):\n",
    "        p4_feature_matrix[ix][0] = song['acousticness']\n",
    "        p4_feature_matrix[ix][1] = song['danceability']\n",
    "        p4_feature_matrix[ix][2] = song['energy']\n",
    "        p4_feature_matrix[ix][3] = song['instrumentalness']\n",
    "        p4_feature_matrix[ix][4] = song['key']\n",
    "        p4_feature_matrix[ix][5] = song['liveness']\n",
    "        p4_feature_matrix[ix][6] = song['loudness']\n",
    "        p4_feature_matrix[ix][7] = song['mode']\n",
    "        p4_feature_matrix[ix][8] = song['tempo']\n",
    "        p4_feature_matrix[ix][9] = song['time_signature']\n",
    "        p4_feature_matrix[ix][10] = song['valence']\n",
    "        p4_feature_matrix[ix][11] = song['duration_ms']\n",
    "                        \n",
    "    p4_feature_median = np.percentile(p4_feature_matrix,50,axis=0)\n",
    "           \n",
    "    playlist_data = pd.Series({\n",
    "                    #'followers': followers,\n",
    "                    #'names' : names,\n",
    "                    #'playlist_id' : playlist_ids,\n",
    "                    'total_tracks' : len(list_of_tracks),\n",
    "                    #'featured' : featured,\n",
    "                    'acousticness': p1_feature_median[0],\n",
    "                    'danceability': p1_feature_median[1],\n",
    "                    'energy': p1_feature_median[2],\n",
    "                    'instrumentalness': p1_feature_median[3],\n",
    "                    'key': p1_feature_median[4],\n",
    "                    'liveness': p1_feature_median[5],\n",
    "                    'loudness': p1_feature_median[6],\n",
    "                    'mode': p1_feature_median[7],\n",
    "                    'tempo': p1_feature_median[8],\n",
    "                    'time_signature': p1_feature_median[9],\n",
    "                    'valence': p1_feature_median[10],\n",
    "                    'duration': p1_feature_median[11],\n",
    "                    'popularity':np.mean(t_pop),\n",
    "                    'mean_num_markets': np.mean(t_av_num_markets),\n",
    "                    #'avg_years' : t_release_date,\n",
    "\n",
    "                    'p1_acousticness': p1_feature_median[0],\n",
    "                    'p1_danceability': p1_feature_median[1],\n",
    "                    'p1_energy': p1_feature_median[2],\n",
    "                    'p1_instrumentalness': p1_feature_median[3],\n",
    "                    'p1_key': p1_feature_median[4],\n",
    "                    'p1_liveness': p1_feature_median[5],\n",
    "                    'p1_loudness': p1_feature_median[6],\n",
    "                    'p1_mode': p1_feature_median[7],\n",
    "                    'p1_tempo': p1_feature_median[8],\n",
    "                    'p1_time_signature': p1_feature_median[9],\n",
    "                    'p1_valence': p1_feature_median[10],\n",
    "                    'p1_duration': p1_feature_median[11],\n",
    "                    'p1_popularity': p1_pop,\n",
    "                    'p1_mean_num_markets': p1_av_num_markets,\n",
    "                    #'p1_avg_years': p1_release_date,\n",
    "\n",
    "                    'p2_acousticness': p2_feature_median[0],\n",
    "                    'p2_danceability': p2_feature_median[1],\n",
    "                    'p2_energy': p2_feature_median[2],\n",
    "                    'p2_instrumentalness': p2_feature_median[3],\n",
    "                    'p2_key': p2_feature_median[4],\n",
    "                    'p2_liveness': p2_feature_median[5],\n",
    "                    'p2_loudness': p2_feature_median[6],\n",
    "                    'p2_mode': p2_feature_median[7],\n",
    "                    'p2_tempo': p2_feature_median[8],\n",
    "                    'p2_time_signature': p2_feature_median[9],\n",
    "                    'p2_valence': p2_feature_median[10],\n",
    "                    'p2_duration': p2_feature_median[11],\n",
    "                    'p2_popularity': p2_pop,\n",
    "                    'p2_mean_num_markets': p2_av_num_markets,\n",
    "                    #'p2_avg_years': p2_release_date,\n",
    "\n",
    "                    'p3_acousticness': p3_feature_median[0],\n",
    "                    'p3_danceability': p3_feature_median[1],\n",
    "                    'p3_energy': p3_feature_median[2],\n",
    "                    'p3_instrumentalness': p3_feature_median[3],\n",
    "                    'p3_key': p3_feature_median[4],\n",
    "                    'p3_liveness': p3_feature_median[5],\n",
    "                    'p3_loudness': p3_feature_median[6],\n",
    "                    'p3_mode': p3_feature_median[7],\n",
    "                    'p3_tempo': p3_feature_median[8],\n",
    "                    'p3_time_signature': p3_feature_median[9],\n",
    "                    'p3_valence': p3_feature_median[10],\n",
    "                    'p3_duration': p3_feature_median[11],\n",
    "                    'p3_popularity': p3_pop,\n",
    "                    'p3_mean_num_markets': p3_av_num_markets,\n",
    "                    #'p3_avg_years': p3_release_date,\n",
    "\n",
    "                    'p4_acousticness': p4_feature_median[0],\n",
    "                    'p4_danceability': p4_feature_median[1],\n",
    "                    'p4_energy': p4_feature_median[2],\n",
    "                    'p4_instrumentalness': p4_feature_median[3],\n",
    "                    'p4_key': p4_feature_median[4],\n",
    "                    'p4_liveness': p4_feature_median[5],\n",
    "                    'p4_loudness': p4_feature_median[6],\n",
    "                    'p4_mode': p4_feature_median[7],\n",
    "                    'p4_tempo': p4_feature_median[8],\n",
    "                    'p4_time_signature': p4_feature_median[9],\n",
    "                    'p4_valence': p4_feature_median[10],\n",
    "                    'p4_duration': p4_feature_median[11],\n",
    "                    'p4_popularity': p4_pop,\n",
    "                    'p4_mean_num_markets': p4_av_num_markets\n",
    "                    #'p4_avg_years': p4_release_date\n",
    "        })\n",
    "    return playlist_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = sp.track('6rqhFgbbKwnb9MLmUQDhG6')\n",
    "test['available_markets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_tracks = ['5BtjqPsi2Mgg9OGBh4lQnh','12IoBmDGa1jVnFrsaFYxY3','2h19P4PvzSs1Sp7gqZvzWg',\n",
    "                 '0qweeIYNNLMlGrX4czWMi1','2yYIKbcr1CelmIteDzEAFD','19dbOzZNsQPRYbgaCqZaAm',\n",
    "                 '69sjO8JHcKM2dG8IezfzfJ']\n",
    "playlist = gen_score(list_of_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=29, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RFC(n_estimators = 100, max_depth = 29)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist.values[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26,  0.25,  0.23,  0.17,  0.09])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problist = rfc.predict_proba(playlist.reshape(1,-1))[0]\n",
    "problist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acousticness             0.852\n",
       "danceability            0.5835\n",
       "duration                 69063\n",
       "energy                   0.417\n",
       "featured                 False\n",
       "instrumentalness             0\n",
       "key                       10.5\n",
       "liveness                 0.326\n",
       "loudness                -9.223\n",
       "mean_num_markets          40.8\n",
       "mode                         1\n",
       "p1_acousticness          0.852\n",
       "p1_danceability         0.5835\n",
       "p1_duration              69063\n",
       "p1_energy                0.417\n",
       "p1_instrumentalness          0\n",
       "p1_key                    10.5\n",
       "p1_liveness              0.326\n",
       "p1_loudness             -9.223\n",
       "p1_mean_num_markets    35.1667\n",
       "p1_mode                      1\n",
       "p1_popularity          3.66667\n",
       "p1_tempo               130.658\n",
       "p1_time_signature          3.5\n",
       "p1_valence               0.823\n",
       "p2_acousticness          0.826\n",
       "p2_danceability          0.569\n",
       "p2_duration             113354\n",
       "p2_energy                0.477\n",
       "p2_instrumentalness          0\n",
       "                        ...   \n",
       "p3_energy               0.4765\n",
       "p3_instrumentalness          0\n",
       "p3_key                       6\n",
       "p3_liveness             0.2715\n",
       "p3_loudness            -10.178\n",
       "p3_mean_num_markets       54.5\n",
       "p3_mode                      1\n",
       "p3_popularity          2.83333\n",
       "p3_tempo                 94.96\n",
       "p3_time_signature            3\n",
       "p3_valence               0.893\n",
       "p4_acousticness          0.798\n",
       "p4_danceability          0.506\n",
       "p4_duration              94093\n",
       "p4_energy                  0.5\n",
       "p4_instrumentalness          0\n",
       "p4_key                       3\n",
       "p4_liveness              0.531\n",
       "p4_loudness            -10.753\n",
       "p4_mean_num_markets    34.5714\n",
       "p4_mode                      1\n",
       "p4_popularity          2.85714\n",
       "p4_tempo               132.036\n",
       "p4_time_signature            4\n",
       "p4_valence               0.668\n",
       "popularity                3.68\n",
       "tempo                  130.658\n",
       "time_signature             3.5\n",
       "total_tracks                25\n",
       "valence                  0.823\n",
       "Name: 1672, dtype: object"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True,\n",
       "            class_weight={1: 4, 2: 1, 3: 1, 4: 1, 5: 1}, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RFC(n_estimators = 100, class_weight={1: 4, 2:1, 3:1, 4:1, 5:1})\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarabboud1/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n",
      "/Users/omarabboud1/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000920810313076\n",
      "0.621268656716\n"
     ]
    }
   ],
   "source": [
    "tr_preds = []\n",
    "for row in X_train.iterrows():\n",
    "    tr_preds.append(int(rfc.predict(row[1].reshape(1,-1))))\n",
    "    \n",
    "te_preds = []\n",
    "for row in X_test.iterrows():\n",
    "    te_preds.append(int(rfc.predict(row[1].reshape(1,-1)))) \n",
    "    \n",
    "print misclass_rate(tr_preds, list(y_train))\n",
    "print misclass_rate(te_preds, list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03 ,  0.7  ,  0.11 ,  0.13 ,  0.03 ],\n",
       "       [ 0.08 ,  0.68 ,  0.06 ,  0.06 ,  0.12 ],\n",
       "       [ 0.11 ,  0.67 ,  0.04 ,  0.15 ,  0.03 ],\n",
       "       ..., \n",
       "       [ 0.06 ,  0.04 ,  0.05 ,  0.02 ,  0.83 ],\n",
       "       [ 0.074,  0.744,  0.072,  0.08 ,  0.03 ],\n",
       "       [ 0.02 ,  0.07 ,  0.65 ,  0.06 ,  0.2  ]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = rfc.predict_proba(X_test)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_probas = []\n",
    "for item in p:\n",
    "    a = item\n",
    "    if list(item).index(max(item)) == 0:\n",
    "        a[0] = 0\n",
    "        new_probas.append(a)\n",
    "    else:\n",
    "        new_probas.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_preds(probas):\n",
    "    preds = []\n",
    "    for a in probas:\n",
    "        preds.append(a.index(max(a)) + 1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = gen_preds(new_probas)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6753731343283582"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass_rate(new, list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.17,  0.19,  0.25,  0.21,  0.18]),\n",
       " array([ 0.03,  0.1 ,  0.06,  0.12,  0.69]),\n",
       " array([ 0.21,  0.29,  0.17,  0.21,  0.12]),\n",
       " array([ 0.  ,  0.26,  0.21,  0.14,  0.07]),\n",
       " array([ 0.16,  0.29,  0.29,  0.19,  0.07]),\n",
       " array([ 0.13,  0.21,  0.28,  0.18,  0.2 ]),\n",
       " array([ 0.  ,  0.19,  0.19,  0.17,  0.15]),\n",
       " array([ 0.18,  0.18,  0.24,  0.13,  0.27]),\n",
       " array([ 0.13,  0.21,  0.28,  0.11,  0.27]),\n",
       " array([ 0.  ,  0.25,  0.15,  0.27,  0.02]),\n",
       " array([ 0.05,  0.18,  0.21,  0.24,  0.32]),\n",
       " array([ 0.  ,  0.27,  0.15,  0.14,  0.04]),\n",
       " array([ 0.11,  0.11,  0.63,  0.09,  0.06]),\n",
       " array([ 0.06,  0.67,  0.05,  0.15,  0.07]),\n",
       " array([ 0.03,  0.18,  0.05,  0.09,  0.65]),\n",
       " array([ 0.11,  0.23,  0.14,  0.13,  0.39]),\n",
       " array([ 0.  ,  0.13,  0.15,  0.22,  0.25]),\n",
       " array([ 0.07,  0.22,  0.18,  0.08,  0.45]),\n",
       " array([ 0.23,  0.21,  0.41,  0.15,  0.  ]),\n",
       " array([ 0.  ,  0.21,  0.09,  0.1 ,  0.04]),\n",
       " array([ 0.2 ,  0.24,  0.16,  0.36,  0.04]),\n",
       " array([ 0.03      ,  0.42333333,  0.49666667,  0.05      ,  0.        ]),\n",
       " array([ 0.22,  0.21,  0.25,  0.26,  0.06]),\n",
       " array([ 0.08,  0.28,  0.23,  0.25,  0.16]),\n",
       " array([ 0.19,  0.23,  0.21,  0.29,  0.08]),\n",
       " array([ 0.11,  0.15,  0.21,  0.21,  0.32]),\n",
       " array([ 0.  ,  0.27,  0.23,  0.1 ,  0.09]),\n",
       " array([ 0.21,  0.36,  0.2 ,  0.18,  0.05]),\n",
       " array([ 0.  ,  0.23,  0.19,  0.25,  0.06]),\n",
       " array([ 0.25,  0.25,  0.27,  0.18,  0.05]),\n",
       " array([ 0.08,  0.22,  0.25,  0.14,  0.31]),\n",
       " array([ 0.06,  0.12,  0.12,  0.13,  0.57]),\n",
       " array([ 0.16,  0.17,  0.22,  0.23,  0.22]),\n",
       " array([ 0.  ,  0.25,  0.16,  0.22,  0.05]),\n",
       " array([ 0.1 ,  0.08,  0.12,  0.22,  0.48]),\n",
       " array([ 0.13,  0.07,  0.48,  0.3 ,  0.02]),\n",
       " array([ 0.11,  0.26,  0.27,  0.28,  0.08]),\n",
       " array([ 0.14,  0.37,  0.12,  0.13,  0.24]),\n",
       " array([ 0.  ,  0.13,  0.26,  0.16,  0.17]),\n",
       " array([ 0.05,  0.22,  0.06,  0.05,  0.62]),\n",
       " array([ 0.18,  0.16,  0.22,  0.23,  0.21]),\n",
       " array([ 0.16,  0.17,  0.14,  0.17,  0.36]),\n",
       " array([ 0.22,  0.14,  0.18,  0.09,  0.37]),\n",
       " array([ 0.19,  0.22,  0.12,  0.08,  0.39]),\n",
       " array([ 0.16,  0.21,  0.23,  0.26,  0.14]),\n",
       " array([ 0.07,  0.14,  0.17,  0.2 ,  0.42]),\n",
       " array([ 0.04,  0.19,  0.12,  0.1 ,  0.55]),\n",
       " array([ 0.2 ,  0.33,  0.29,  0.12,  0.06]),\n",
       " array([ 0.15,  0.2 ,  0.22,  0.19,  0.24]),\n",
       " array([ 0.22,  0.15,  0.18,  0.22,  0.23]),\n",
       " array([ 0.  ,  0.16,  0.21,  0.2 ,  0.15]),\n",
       " array([ 0.   ,  0.215,  0.185,  0.21 ,  0.06 ]),\n",
       " array([ 0.    ,  0.1475,  0.2325,  0.23  ,  0.12  ]),\n",
       " array([ 0.01,  0.2 ,  0.21,  0.18,  0.4 ]),\n",
       " array([ 0.  ,  0.06,  0.12,  0.25,  0.16]),\n",
       " array([ 0.  ,  0.19,  0.19,  0.19,  0.11]),\n",
       " array([ 0.2 ,  0.14,  0.17,  0.17,  0.32]),\n",
       " array([ 0.15,  0.12,  0.25,  0.24,  0.24]),\n",
       " array([ 0.  ,  0.18,  0.15,  0.21,  0.14]),\n",
       " array([ 0.07,  0.25,  0.08,  0.2 ,  0.4 ]),\n",
       " array([ 0.  ,  0.09,  0.09,  0.05,  0.02]),\n",
       " array([ 0.  ,  0.2 ,  0.22,  0.17,  0.05]),\n",
       " array([ 0.23,  0.16,  0.27,  0.21,  0.13]),\n",
       " array([ 0.08,  0.36,  0.15,  0.08,  0.33]),\n",
       " array([ 0.22,  0.16,  0.11,  0.36,  0.15]),\n",
       " array([ 0.11,  0.24,  0.3 ,  0.32,  0.03]),\n",
       " array([ 0.23,  0.17,  0.24,  0.26,  0.1 ]),\n",
       " array([ 0.2 ,  0.28,  0.21,  0.17,  0.14]),\n",
       " array([ 0.09,  0.23,  0.16,  0.44,  0.08]),\n",
       " array([ 0.17,  0.15,  0.09,  0.2 ,  0.39]),\n",
       " array([ 0.17,  0.21,  0.26,  0.26,  0.1 ]),\n",
       " array([ 0.02,  0.3 ,  0.31,  0.18,  0.19]),\n",
       " array([ 0.03,  0.31,  0.27,  0.09,  0.3 ]),\n",
       " array([ 0.  ,  0.17,  0.18,  0.28,  0.08]),\n",
       " array([ 0.  ,  0.22,  0.22,  0.23,  0.08]),\n",
       " array([ 0.03,  0.28,  0.18,  0.13,  0.38]),\n",
       " array([ 0.16,  0.22,  0.15,  0.24,  0.23]),\n",
       " array([ 0.  ,  0.19,  0.15,  0.1 ,  0.07]),\n",
       " array([ 0.05,  0.23,  0.17,  0.21,  0.34]),\n",
       " array([ 0.  ,  0.18,  0.24,  0.08,  0.22]),\n",
       " array([ 0.03,  0.15,  0.13,  0.1 ,  0.59]),\n",
       " array([ 0.  ,  0.23,  0.27,  0.2 ,  0.02]),\n",
       " array([ 0.13,  0.2 ,  0.25,  0.28,  0.14]),\n",
       " array([ 0.15      ,  0.19666667,  0.20333333,  0.21      ,  0.24      ]),\n",
       " array([ 0.  ,  0.17,  0.15,  0.22,  0.14]),\n",
       " array([ 0.26,  0.13,  0.33,  0.19,  0.09]),\n",
       " array([ 0.17,  0.18,  0.27,  0.22,  0.16]),\n",
       " array([ 0.12,  0.14,  0.12,  0.13,  0.49]),\n",
       " array([ 0.1 ,  0.18,  0.53,  0.18,  0.01]),\n",
       " array([ 0.16,  0.22,  0.11,  0.14,  0.37]),\n",
       " array([ 0.  ,  0.19,  0.22,  0.21,  0.03]),\n",
       " array([ 0.  ,  0.18,  0.2 ,  0.17,  0.07]),\n",
       " array([ 0.  ,  0.13,  0.1 ,  0.13,  0.21]),\n",
       " array([ 0.09,  0.27,  0.25,  0.16,  0.23]),\n",
       " array([ 0.22,  0.1 ,  0.13,  0.21,  0.34]),\n",
       " array([ 0.22,  0.18,  0.25,  0.23,  0.12]),\n",
       " array([ 0.18,  0.22,  0.21,  0.22,  0.17]),\n",
       " array([ 0.  ,  0.1 ,  0.17,  0.18,  0.01]),\n",
       " array([ 0.24,  0.22,  0.39,  0.08,  0.07]),\n",
       " array([ 0.28,  0.17,  0.39,  0.14,  0.02]),\n",
       " array([ 0.        ,  0.15933333,  0.24066667,  0.12      ,  0.08      ]),\n",
       " array([ 0.17,  0.13,  0.17,  0.2 ,  0.33]),\n",
       " array([ 0.27,  0.2 ,  0.43,  0.06,  0.04]),\n",
       " array([ 0.18,  0.12,  0.31,  0.21,  0.18]),\n",
       " array([ 0.13,  0.18,  0.09,  0.07,  0.53]),\n",
       " array([ 0.  ,  0.16,  0.23,  0.19,  0.06]),\n",
       " array([ 0.18,  0.2 ,  0.21,  0.17,  0.24]),\n",
       " array([ 0.  ,  0.23,  0.17,  0.16,  0.01]),\n",
       " array([ 0.1 ,  0.23,  0.44,  0.19,  0.04]),\n",
       " array([ 0.05,  0.15,  0.45,  0.32,  0.03]),\n",
       " array([ 0.03,  0.29,  0.09,  0.11,  0.48]),\n",
       " array([ 0.27,  0.38,  0.11,  0.17,  0.07]),\n",
       " array([ 0.09,  0.18,  0.1 ,  0.08,  0.55]),\n",
       " array([ 0.17,  0.15,  0.13,  0.17,  0.38]),\n",
       " array([ 0.2 ,  0.13,  0.17,  0.36,  0.14]),\n",
       " array([ 0.04,  0.12,  0.65,  0.18,  0.01]),\n",
       " array([ 0.17,  0.19,  0.36,  0.24,  0.04]),\n",
       " array([ 0.03,  0.29,  0.12,  0.06,  0.5 ]),\n",
       " array([ 0.  ,  0.2 ,  0.28,  0.14,  0.05]),\n",
       " array([ 0.15,  0.18,  0.29,  0.24,  0.14]),\n",
       " array([ 0.06,  0.19,  0.28,  0.22,  0.25]),\n",
       " array([ 0.  ,  0.15,  0.35,  0.13,  0.02]),\n",
       " array([ 0.  ,  0.23,  0.14,  0.16,  0.23]),\n",
       " array([ 0.03,  0.34,  0.4 ,  0.21,  0.02]),\n",
       " array([ 0.16,  0.26,  0.22,  0.2 ,  0.16]),\n",
       " array([ 0.08,  0.18,  0.13,  0.07,  0.54]),\n",
       " array([ 0.  ,  0.17,  0.2 ,  0.17,  0.21]),\n",
       " array([ 0.12,  0.19,  0.19,  0.13,  0.37]),\n",
       " array([ 0.16,  0.34,  0.27,  0.13,  0.1 ]),\n",
       " array([ 0.  ,  0.11,  0.12,  0.16,  0.28]),\n",
       " array([ 0.13,  0.19,  0.11,  0.22,  0.35]),\n",
       " array([ 0.  ,  0.22,  0.15,  0.22,  0.18]),\n",
       " array([ 0.18,  0.23,  0.13,  0.11,  0.35]),\n",
       " array([ 0.15,  0.26,  0.1 ,  0.14,  0.35]),\n",
       " array([ 0.03,  0.16,  0.14,  0.11,  0.56]),\n",
       " array([ 0.27,  0.15,  0.14,  0.16,  0.28]),\n",
       " array([ 0.04,  0.31,  0.11,  0.19,  0.35]),\n",
       " array([ 0.14,  0.19,  0.27,  0.19,  0.21]),\n",
       " array([ 0.19,  0.23,  0.21,  0.21,  0.16]),\n",
       " array([ 0.14,  0.14,  0.11,  0.3 ,  0.31]),\n",
       " array([ 0.14,  0.26,  0.24,  0.22,  0.14]),\n",
       " array([ 0.        ,  0.21333333,  0.21666667,  0.19      ,  0.12      ]),\n",
       " array([ 0.26,  0.34,  0.12,  0.22,  0.06]),\n",
       " array([ 0.  ,  0.21,  0.23,  0.26,  0.04]),\n",
       " array([ 0.  ,  0.21,  0.29,  0.11,  0.03]),\n",
       " array([ 0.11,  0.29,  0.27,  0.16,  0.17]),\n",
       " array([ 0.17,  0.15,  0.13,  0.11,  0.44]),\n",
       " array([ 0.11,  0.21,  0.32,  0.13,  0.23]),\n",
       " array([ 0.15,  0.21,  0.41,  0.16,  0.07]),\n",
       " array([ 0.09,  0.11,  0.09,  0.13,  0.58]),\n",
       " array([ 0.13,  0.07,  0.2 ,  0.13,  0.47]),\n",
       " array([ 0.11,  0.22,  0.26,  0.26,  0.15]),\n",
       " array([ 0.  ,  0.09,  0.19,  0.18,  0.09]),\n",
       " array([ 0.  ,  0.18,  0.22,  0.23,  0.12]),\n",
       " array([ 0.03,  0.12,  0.65,  0.18,  0.02]),\n",
       " array([ 0.03,  0.1 ,  0.07,  0.07,  0.73]),\n",
       " array([ 0.  ,  0.21,  0.24,  0.14,  0.05]),\n",
       " array([ 0.11,  0.07,  0.52,  0.22,  0.08]),\n",
       " array([ 0.13,  0.18,  0.14,  0.16,  0.39]),\n",
       " array([ 0.26,  0.19,  0.36,  0.17,  0.02]),\n",
       " array([ 0.11,  0.23,  0.14,  0.16,  0.36]),\n",
       " array([ 0.08,  0.11,  0.2 ,  0.32,  0.29]),\n",
       " array([ 0.  ,  0.19,  0.18,  0.14,  0.09]),\n",
       " array([ 0.16,  0.32,  0.19,  0.14,  0.19]),\n",
       " array([ 0.  ,  0.18,  0.29,  0.16,  0.02]),\n",
       " array([ 0.  ,  0.17,  0.2 ,  0.22,  0.08]),\n",
       " array([ 0.  ,  0.17,  0.17,  0.13,  0.01]),\n",
       " array([ 0.09,  0.18,  0.24,  0.15,  0.34]),\n",
       " array([ 0.16,  0.15,  0.16,  0.13,  0.4 ]),\n",
       " array([ 0.13,  0.17,  0.2 ,  0.29,  0.21]),\n",
       " array([ 0.12,  0.22,  0.21,  0.16,  0.29]),\n",
       " array([ 0.04,  0.26,  0.1 ,  0.16,  0.44]),\n",
       " array([ 0.12,  0.32,  0.21,  0.18,  0.17]),\n",
       " array([ 0.2 ,  0.2 ,  0.25,  0.21,  0.14]),\n",
       " array([ 0.  ,  0.09,  0.24,  0.13,  0.04]),\n",
       " array([ 0.  ,  0.27,  0.18,  0.17,  0.06]),\n",
       " array([ 0.11,  0.17,  0.21,  0.25,  0.26]),\n",
       " array([ 0.25,  0.26,  0.25,  0.15,  0.09]),\n",
       " array([ 0.13,  0.09,  0.07,  0.14,  0.57]),\n",
       " array([ 0.07,  0.18,  0.05,  0.17,  0.53]),\n",
       " array([ 0.12,  0.21,  0.14,  0.12,  0.41]),\n",
       " array([ 0.  ,  0.22,  0.13,  0.08,  0.05]),\n",
       " array([ 0.26      ,  0.27333333,  0.15666667,  0.26      ,  0.05      ]),\n",
       " array([ 0.  ,  0.2 ,  0.23,  0.17,  0.12]),\n",
       " array([ 0.15,  0.23,  0.15,  0.09,  0.38]),\n",
       " array([ 0.09,  0.14,  0.2 ,  0.22,  0.35]),\n",
       " array([ 0.15,  0.16,  0.28,  0.19,  0.22]),\n",
       " array([ 0.02,  0.18,  0.13,  0.28,  0.39]),\n",
       " array([ 0.12,  0.15,  0.38,  0.31,  0.04]),\n",
       " array([ 0.1 ,  0.19,  0.16,  0.31,  0.24]),\n",
       " array([ 0.  ,  0.28,  0.15,  0.18,  0.11]),\n",
       " array([ 0.  ,  0.16,  0.24,  0.13,  0.06]),\n",
       " array([ 0.02,  0.15,  0.35,  0.32,  0.16]),\n",
       " array([ 0.08,  0.22,  0.23,  0.16,  0.31]),\n",
       " array([ 0.09,  0.33,  0.12,  0.15,  0.31]),\n",
       " array([ 0.1 ,  0.21,  0.09,  0.22,  0.38]),\n",
       " array([ 0.28,  0.29,  0.17,  0.18,  0.08]),\n",
       " array([ 0.2 ,  0.22,  0.21,  0.25,  0.12]),\n",
       " array([ 0.08,  0.24,  0.42,  0.23,  0.03]),\n",
       " array([ 0.24,  0.14,  0.19,  0.05,  0.38]),\n",
       " array([ 0.  ,  0.11,  0.09,  0.26,  0.19]),\n",
       " array([ 0.25,  0.21,  0.26,  0.21,  0.07]),\n",
       " array([ 0.  ,  0.19,  0.2 ,  0.21,  0.18]),\n",
       " array([ 0.  ,  0.16,  0.14,  0.16,  0.2 ]),\n",
       " array([ 0.15      ,  0.27666667,  0.19333333,  0.18      ,  0.2       ]),\n",
       " array([ 0.  ,  0.12,  0.15,  0.12,  0.03]),\n",
       " array([ 0.17,  0.25,  0.18,  0.18,  0.22]),\n",
       " array([ 0.12,  0.2 ,  0.1 ,  0.37,  0.21]),\n",
       " array([ 0.09,  0.26,  0.23,  0.07,  0.35]),\n",
       " array([ 0.04,  0.12,  0.62,  0.21,  0.01]),\n",
       " array([ 0.  ,  0.17,  0.26,  0.16,  0.03]),\n",
       " array([ 0.31,  0.16,  0.1 ,  0.06,  0.37]),\n",
       " array([ 0.  ,  0.12,  0.1 ,  0.07,  0.14]),\n",
       " array([ 0.05,  0.11,  0.12,  0.13,  0.59]),\n",
       " array([ 0.07,  0.28,  0.3 ,  0.27,  0.08]),\n",
       " array([ 0.04,  0.08,  0.7 ,  0.16,  0.02]),\n",
       " array([ 0.  ,  0.23,  0.28,  0.14,  0.05]),\n",
       " array([ 0.07,  0.3 ,  0.12,  0.31,  0.2 ]),\n",
       " array([ 0.13,  0.23,  0.37,  0.18,  0.09]),\n",
       " array([ 0.15,  0.28,  0.3 ,  0.18,  0.09]),\n",
       " array([ 0.12,  0.21,  0.15,  0.11,  0.41]),\n",
       " array([ 0.09,  0.19,  0.1 ,  0.06,  0.56]),\n",
       " array([ 0.12      ,  0.23666667,  0.19333333,  0.22      ,  0.23      ]),\n",
       " array([ 0.13,  0.13,  0.21,  0.27,  0.26]),\n",
       " array([ 0.19,  0.23,  0.19,  0.15,  0.24]),\n",
       " array([ 0.17,  0.2 ,  0.16,  0.18,  0.29]),\n",
       " array([ 0.17,  0.26,  0.21,  0.12,  0.24]),\n",
       " array([ 0.  ,  0.22,  0.21,  0.14,  0.02]),\n",
       " array([ 0.3 ,  0.09,  0.37,  0.18,  0.06]),\n",
       " array([ 0.2 ,  0.18,  0.25,  0.17,  0.2 ]),\n",
       " array([ 0.12,  0.18,  0.22,  0.28,  0.2 ]),\n",
       " array([ 0.  ,  0.24,  0.21,  0.16,  0.05]),\n",
       " array([ 0.07,  0.13,  0.17,  0.17,  0.46]),\n",
       " array([ 0.11,  0.07,  0.1 ,  0.08,  0.64]),\n",
       " array([ 0.  ,  0.09,  0.21,  0.17,  0.03]),\n",
       " array([ 0.  ,  0.14,  0.08,  0.19,  0.04]),\n",
       " array([ 0.  ,  0.19,  0.13,  0.16,  0.21]),\n",
       " array([ 0.08,  0.18,  0.37,  0.32,  0.05]),\n",
       " array([ 0.  ,  0.09,  0.22,  0.18,  0.16]),\n",
       " array([ 0.13,  0.36,  0.15,  0.27,  0.09]),\n",
       " array([ 0.  ,  0.06,  0.16,  0.12,  0.  ]),\n",
       " array([ 0.15,  0.17,  0.13,  0.07,  0.48]),\n",
       " array([ 0.02,  0.16,  0.46,  0.33,  0.03]),\n",
       " array([ 0.13,  0.27,  0.21,  0.28,  0.11]),\n",
       " array([ 0.  ,  0.14,  0.19,  0.13,  0.21]),\n",
       " array([ 0.24,  0.23,  0.32,  0.12,  0.09]),\n",
       " array([ 0.17,  0.29,  0.24,  0.12,  0.18]),\n",
       " array([ 0.16,  0.28,  0.16,  0.17,  0.23]),\n",
       " array([ 0.  ,  0.22,  0.12,  0.08,  0.24]),\n",
       " array([ 0.  ,  0.18,  0.17,  0.2 ,  0.03]),\n",
       " array([ 0.15,  0.24,  0.25,  0.19,  0.17]),\n",
       " array([ 0.04,  0.31,  0.13,  0.13,  0.39]),\n",
       " array([ 0.05,  0.18,  0.26,  0.42,  0.09]),\n",
       " array([ 0.  ,  0.24,  0.11,  0.17,  0.05]),\n",
       " array([ 0.15,  0.19,  0.11,  0.13,  0.42]),\n",
       " array([ 0.  ,  0.17,  0.16,  0.09,  0.04]),\n",
       " array([ 0.05,  0.19,  0.04,  0.15,  0.57]),\n",
       " array([ 0.2 ,  0.13,  0.1 ,  0.12,  0.45]),\n",
       " array([ 0.25,  0.21,  0.31,  0.14,  0.09]),\n",
       " array([ 0.08,  0.21,  0.17,  0.26,  0.28]),\n",
       " array([ 0.06,  0.15,  0.12,  0.09,  0.58]),\n",
       " array([ 0.13,  0.24,  0.25,  0.14,  0.24]),\n",
       " array([ 0.13,  0.17,  0.18,  0.23,  0.29]),\n",
       " array([ 0.  ,  0.21,  0.17,  0.25,  0.08]),\n",
       " array([ 0.23,  0.2 ,  0.29,  0.17,  0.11]),\n",
       " array([ 0.        ,  0.22333333,  0.19666667,  0.12      ,  0.21      ]),\n",
       " array([ 0.17      ,  0.20333333,  0.29666667,  0.11      ,  0.22      ]),\n",
       " array([ 0.1 ,  0.19,  0.16,  0.17,  0.38]),\n",
       " array([ 0.  ,  0.2 ,  0.2 ,  0.25,  0.02]),\n",
       " array([ 0.  ,  0.24,  0.25,  0.13,  0.06]),\n",
       " array([ 0.06,  0.23,  0.42,  0.27,  0.02]),\n",
       " array([ 0.08,  0.15,  0.51,  0.23,  0.03]),\n",
       " array([ 0.09,  0.23,  0.12,  0.11,  0.45]),\n",
       " array([ 0.  ,  0.26,  0.07,  0.18,  0.17]),\n",
       " array([ 0.02,  0.25,  0.22,  0.19,  0.32]),\n",
       " array([ 0.  ,  0.15,  0.18,  0.2 ,  0.21]),\n",
       " array([ 0.16,  0.21,  0.3 ,  0.16,  0.17]),\n",
       " array([ 0.05,  0.24,  0.41,  0.29,  0.01]),\n",
       " array([ 0.06,  0.22,  0.42,  0.29,  0.01]),\n",
       " array([ 0.18,  0.14,  0.35,  0.14,  0.19]),\n",
       " array([ 0.16,  0.14,  0.17,  0.17,  0.36]),\n",
       " array([ 0.02,  0.1 ,  0.57,  0.25,  0.06]),\n",
       " array([ 0.04,  0.08,  0.09,  0.08,  0.71]),\n",
       " array([ 0.08,  0.24,  0.11,  0.07,  0.5 ]),\n",
       " array([ 0.06,  0.1 ,  0.13,  0.11,  0.6 ]),\n",
       " array([ 0.08,  0.18,  0.14,  0.19,  0.41]),\n",
       " array([ 0.  ,  0.2 ,  0.15,  0.14,  0.07]),\n",
       " array([ 0.14,  0.25,  0.25,  0.13,  0.23]),\n",
       " array([ 0.  ,  0.21,  0.2 ,  0.15,  0.05]),\n",
       " array([ 0.08,  0.21,  0.08,  0.35,  0.28]),\n",
       " array([ 0.2 ,  0.25,  0.32,  0.17,  0.06]),\n",
       " array([ 0.16,  0.13,  0.1 ,  0.21,  0.4 ]),\n",
       " array([ 0.  ,  0.25,  0.17,  0.2 ,  0.04]),\n",
       " array([ 0.23,  0.19,  0.23,  0.26,  0.09]),\n",
       " array([ 0.15,  0.2 ,  0.11,  0.16,  0.38]),\n",
       " array([ 0.08,  0.3 ,  0.28,  0.27,  0.07]),\n",
       " array([ 0.18,  0.29,  0.24,  0.23,  0.06]),\n",
       " array([ 0.18,  0.16,  0.28,  0.2 ,  0.18]),\n",
       " array([ 0.03,  0.18,  0.45,  0.29,  0.05]),\n",
       " array([ 0.  ,  0.13,  0.28,  0.28,  0.03]),\n",
       " array([ 0.  ,  0.2 ,  0.17,  0.16,  0.23]),\n",
       " array([ 0.  ,  0.2 ,  0.14,  0.24,  0.01]),\n",
       " array([ 0.05,  0.15,  0.12,  0.12,  0.56]),\n",
       " array([ 0.21,  0.2 ,  0.22,  0.12,  0.25]),\n",
       " array([ 0.07,  0.12,  0.09,  0.3 ,  0.42]),\n",
       " array([ 0.  ,  0.18,  0.19,  0.11,  0.2 ]),\n",
       " array([ 0.19,  0.14,  0.23,  0.11,  0.33]),\n",
       " array([ 0.  ,  0.21,  0.2 ,  0.2 ,  0.09]),\n",
       " array([ 0.05,  0.23,  0.41,  0.29,  0.02]),\n",
       " array([ 0.1 ,  0.23,  0.19,  0.18,  0.3 ]),\n",
       " array([ 0.22,  0.21,  0.14,  0.14,  0.29]),\n",
       " array([ 0.  ,  0.2 ,  0.24,  0.18,  0.14]),\n",
       " array([ 0.  ,  0.14,  0.06,  0.04,  0.  ]),\n",
       " array([ 0.17,  0.18,  0.14,  0.21,  0.3 ]),\n",
       " array([ 0.  ,  0.14,  0.23,  0.2 ,  0.12]),\n",
       " array([ 0.1 ,  0.25,  0.31,  0.2 ,  0.14]),\n",
       " array([ 0.18,  0.13,  0.49,  0.18,  0.02]),\n",
       " array([ 0.05,  0.14,  0.49,  0.29,  0.03]),\n",
       " array([ 0.08,  0.2 ,  0.28,  0.34,  0.1 ]),\n",
       " array([ 0.18,  0.31,  0.26,  0.17,  0.08]),\n",
       " array([ 0.11,  0.18,  0.19,  0.2 ,  0.32]),\n",
       " array([ 0.1       ,  0.25666667,  0.14333333,  0.19      ,  0.31      ]),\n",
       " array([ 0.12,  0.2 ,  0.14,  0.12,  0.42]),\n",
       " array([ 0.13,  0.31,  0.24,  0.18,  0.14]),\n",
       " array([ 0.06,  0.16,  0.55,  0.22,  0.01]),\n",
       " array([ 0.  ,  0.15,  0.18,  0.2 ,  0.2 ]),\n",
       " array([ 0.11,  0.2 ,  0.11,  0.25,  0.33]),\n",
       " array([ 0.08,  0.23,  0.29,  0.21,  0.19]),\n",
       " array([ 0.08,  0.23,  0.13,  0.17,  0.39]),\n",
       " array([ 0.21,  0.18,  0.17,  0.12,  0.32]),\n",
       " array([ 0.16,  0.12,  0.39,  0.23,  0.1 ]),\n",
       " array([ 0.1 ,  0.29,  0.19,  0.31,  0.11]),\n",
       " array([ 0.  ,  0.13,  0.14,  0.09,  0.21]),\n",
       " array([ 0.  ,  0.28,  0.17,  0.2 ,  0.07]),\n",
       " array([ 0.  ,  0.23,  0.18,  0.11,  0.04]),\n",
       " array([ 0.06,  0.26,  0.16,  0.31,  0.21]),\n",
       " array([ 0.21,  0.23,  0.14,  0.15,  0.27]),\n",
       " array([ 0.15,  0.14,  0.1 ,  0.12,  0.49]),\n",
       " array([ 0.04,  0.18,  0.45,  0.3 ,  0.03]),\n",
       " array([ 0.04,  0.31,  0.16,  0.06,  0.43]),\n",
       " array([ 0.13,  0.19,  0.13,  0.19,  0.36]),\n",
       " array([ 0.13,  0.17,  0.07,  0.16,  0.47]),\n",
       " array([ 0.  ,  0.25,  0.18,  0.1 ,  0.11]),\n",
       " array([ 0.12,  0.22,  0.27,  0.27,  0.12]),\n",
       " array([ 0.  ,  0.1 ,  0.23,  0.08,  0.  ]),\n",
       " array([ 0.1 ,  0.17,  0.15,  0.13,  0.45]),\n",
       " array([ 0.        ,  0.19583333,  0.23416667,  0.07      ,  0.01      ]),\n",
       " array([ 0.  ,  0.11,  0.07,  0.11,  0.3 ]),\n",
       " array([ 0.02,  0.13,  0.1 ,  0.09,  0.66]),\n",
       " array([ 0.02,  0.23,  0.37,  0.35,  0.03]),\n",
       " array([ 0.18,  0.15,  0.1 ,  0.1 ,  0.47]),\n",
       " array([ 0.15,  0.16,  0.22,  0.18,  0.29]),\n",
       " array([ 0.  ,  0.23,  0.23,  0.15,  0.07]),\n",
       " array([ 0.08      ,  0.15333333,  0.19666667,  0.14      ,  0.43      ]),\n",
       " array([ 0.08,  0.19,  0.13,  0.15,  0.45]),\n",
       " array([ 0.09,  0.2 ,  0.21,  0.14,  0.36]),\n",
       " array([ 0.11,  0.16,  0.15,  0.2 ,  0.38]),\n",
       " array([ 0.12,  0.21,  0.15,  0.08,  0.44]),\n",
       " array([ 0.  ,  0.22,  0.17,  0.11,  0.14]),\n",
       " array([ 0.24,  0.21,  0.2 ,  0.27,  0.08]),\n",
       " array([ 0.18,  0.19,  0.22,  0.16,  0.25]),\n",
       " array([ 0.  ,  0.22,  0.11,  0.22,  0.09]),\n",
       " array([ 0.  ,  0.21,  0.21,  0.16,  0.11]),\n",
       " array([ 0.13,  0.33,  0.19,  0.21,  0.14]),\n",
       " array([ 0.23,  0.25,  0.29,  0.16,  0.07]),\n",
       " array([ 0.13,  0.18,  0.15,  0.16,  0.38]),\n",
       " array([ 0.  ,  0.2 ,  0.13,  0.1 ,  0.01]),\n",
       " array([ 0.  ,  0.19,  0.21,  0.2 ,  0.09]),\n",
       " array([ 0.07,  0.16,  0.19,  0.12,  0.46]),\n",
       " array([ 0.  ,  0.16,  0.18,  0.16,  0.1 ]),\n",
       " array([ 0.14      ,  0.14333333,  0.17666667,  0.34      ,  0.2       ]),\n",
       " array([ 0.09,  0.36,  0.33,  0.13,  0.09]),\n",
       " array([ 0.  ,  0.21,  0.15,  0.14,  0.06]),\n",
       " array([ 0.14,  0.19,  0.21,  0.17,  0.29]),\n",
       " array([ 0.25,  0.18,  0.34,  0.1 ,  0.13]),\n",
       " array([ 0.  ,  0.22,  0.17,  0.16,  0.15]),\n",
       " array([ 0.03,  0.06,  0.61,  0.26,  0.04]),\n",
       " array([ 0.14,  0.22,  0.22,  0.3 ,  0.12]),\n",
       " array([ 0.06,  0.18,  0.51,  0.22,  0.03]),\n",
       " array([ 0.21,  0.21,  0.19,  0.15,  0.24]),\n",
       " array([ 0.08,  0.25,  0.12,  0.23,  0.32]),\n",
       " array([ 0.12,  0.32,  0.22,  0.2 ,  0.14]),\n",
       " array([ 0.21,  0.17,  0.27,  0.24,  0.11]),\n",
       " array([ 0.18,  0.23,  0.23,  0.2 ,  0.16]),\n",
       " array([ 0.16,  0.44,  0.15,  0.18,  0.07]),\n",
       " array([ 0.06,  0.04,  0.07,  0.08,  0.75]),\n",
       " array([ 0.  ,  0.17,  0.18,  0.12,  0.05]),\n",
       " array([ 0.  ,  0.15,  0.19,  0.13,  0.06]),\n",
       " array([ 0.06,  0.14,  0.14,  0.16,  0.5 ]),\n",
       " array([ 0.09,  0.2 ,  0.09,  0.15,  0.47]),\n",
       " array([ 0.  ,  0.15,  0.21,  0.19,  0.02]),\n",
       " array([ 0.08,  0.24,  0.11,  0.07,  0.5 ]),\n",
       " array([ 0.13,  0.23,  0.07,  0.05,  0.52]),\n",
       " array([ 0.04,  0.14,  0.6 ,  0.18,  0.04]),\n",
       " array([ 0.18,  0.22,  0.24,  0.17,  0.19]),\n",
       " array([ 0.12,  0.19,  0.2 ,  0.21,  0.28]),\n",
       " array([ 0.01,  0.19,  0.6 ,  0.15,  0.05]),\n",
       " array([ 0.16,  0.09,  0.15,  0.29,  0.31]),\n",
       " array([ 0.15,  0.23,  0.18,  0.32,  0.12]),\n",
       " array([ 0.  ,  0.23,  0.17,  0.15,  0.01]),\n",
       " array([ 0.08,  0.18,  0.19,  0.19,  0.36]),\n",
       " array([ 0.  ,  0.17,  0.12,  0.24,  0.08]),\n",
       " array([ 0.07,  0.06,  0.07,  0.12,  0.68]),\n",
       " array([ 0.  ,  0.17,  0.25,  0.23,  0.1 ]),\n",
       " array([ 0.  ,  0.18,  0.11,  0.13,  0.23]),\n",
       " array([ 0.01,  0.34,  0.18,  0.45,  0.02]),\n",
       " array([ 0.09,  0.22,  0.17,  0.13,  0.39]),\n",
       " array([ 0.05,  0.14,  0.07,  0.1 ,  0.64]),\n",
       " array([ 0.14,  0.3 ,  0.35,  0.17,  0.04]),\n",
       " array([ 0.17,  0.16,  0.16,  0.14,  0.37]),\n",
       " array([ 0.04,  0.15,  0.7 ,  0.1 ,  0.01]),\n",
       " array([ 0.  ,  0.12,  0.14,  0.22,  0.09]),\n",
       " array([ 0.18,  0.24,  0.13,  0.11,  0.34]),\n",
       " array([ 0.11,  0.2 ,  0.17,  0.31,  0.21]),\n",
       " array([ 0.12,  0.21,  0.19,  0.12,  0.36]),\n",
       " array([ 0.08,  0.16,  0.21,  0.21,  0.34]),\n",
       " array([ 0.  ,  0.18,  0.21,  0.08,  0.04]),\n",
       " array([ 0.05,  0.15,  0.55,  0.21,  0.04]),\n",
       " array([ 0.08,  0.11,  0.22,  0.31,  0.28]),\n",
       " array([ 0.16,  0.27,  0.14,  0.19,  0.24]),\n",
       " array([ 0.07,  0.18,  0.29,  0.36,  0.1 ]),\n",
       " array([ 0.14,  0.24,  0.08,  0.15,  0.39]),\n",
       " array([ 0.25,  0.22,  0.3 ,  0.21,  0.02]),\n",
       " array([ 0.14,  0.29,  0.14,  0.35,  0.08]),\n",
       " array([ 0.11,  0.22,  0.26,  0.21,  0.2 ]),\n",
       " array([ 0.17      ,  0.14666667,  0.26333333,  0.25      ,  0.17      ]),\n",
       " array([ 0.08,  0.2 ,  0.09,  0.14,  0.49]),\n",
       " array([ 0.  ,  0.1 ,  0.09,  0.1 ,  0.03]),\n",
       " array([ 0.15,  0.15,  0.27,  0.26,  0.17]),\n",
       " array([ 0.12,  0.25,  0.26,  0.22,  0.15]),\n",
       " array([ 0.07,  0.16,  0.3 ,  0.23,  0.24]),\n",
       " array([ 0.  ,  0.21,  0.15,  0.17,  0.01]),\n",
       " array([ 0.1 ,  0.28,  0.23,  0.34,  0.05]),\n",
       " array([ 0.25,  0.23,  0.32,  0.15,  0.05]),\n",
       " array([ 0.  ,  0.16,  0.13,  0.1 ,  0.02]),\n",
       " array([ 0.27,  0.18,  0.21,  0.28,  0.06]),\n",
       " array([ 0.08,  0.18,  0.15,  0.25,  0.34]),\n",
       " array([ 0.  ,  0.14,  0.25,  0.19,  0.13]),\n",
       " array([ 0.  ,  0.15,  0.19,  0.12,  0.25]),\n",
       " array([ 0.  ,  0.22,  0.12,  0.24,  0.07]),\n",
       " array([ 0.15,  0.29,  0.26,  0.15,  0.15]),\n",
       " array([ 0.05,  0.33,  0.15,  0.3 ,  0.17]),\n",
       " array([ 0.17,  0.2 ,  0.22,  0.37,  0.04]),\n",
       " array([ 0.  ,  0.17,  0.24,  0.15,  0.09]),\n",
       " array([ 0.2 ,  0.21,  0.18,  0.21,  0.2 ]),\n",
       " array([ 0.15,  0.19,  0.15,  0.16,  0.35]),\n",
       " array([ 0.15,  0.17,  0.18,  0.14,  0.36]),\n",
       " array([ 0.22,  0.27,  0.23,  0.16,  0.12]),\n",
       " array([ 0.  ,  0.24,  0.14,  0.14,  0.05]),\n",
       " array([ 0.25,  0.26,  0.19,  0.12,  0.18]),\n",
       " array([ 0.  ,  0.24,  0.21,  0.11,  0.03]),\n",
       " array([ 0.14,  0.12,  0.1 ,  0.08,  0.56]),\n",
       " array([ 0.21,  0.18,  0.15,  0.16,  0.3 ]),\n",
       " array([ 0.04,  0.29,  0.35,  0.24,  0.08]),\n",
       " array([ 0.23,  0.15,  0.28,  0.3 ,  0.04]),\n",
       " array([ 0.  ,  0.13,  0.21,  0.1 ,  0.06]),\n",
       " array([ 0.  ,  0.22,  0.25,  0.17,  0.03]),\n",
       " array([ 0.  ,  0.25,  0.09,  0.21,  0.04]),\n",
       " array([ 0.14,  0.2 ,  0.24,  0.15,  0.27]),\n",
       " array([ 0.09,  0.22,  0.14,  0.14,  0.41]),\n",
       " array([ 0.  ,  0.19,  0.18,  0.28,  0.06]),\n",
       " array([ 0.11,  0.18,  0.26,  0.31,  0.14]),\n",
       " array([ 0.13,  0.41,  0.18,  0.24,  0.04]),\n",
       " array([ 0.  ,  0.15,  0.19,  0.15,  0.04]),\n",
       " array([ 0.  ,  0.13,  0.16,  0.1 ,  0.05]),\n",
       " array([ 0.  ,  0.15,  0.63,  0.19,  0.03]),\n",
       " array([ 0.  ,  0.26,  0.29,  0.08,  0.04]),\n",
       " array([ 0.2 ,  0.22,  0.24,  0.24,  0.1 ]),\n",
       " array([ 0.  ,  0.2 ,  0.18,  0.22,  0.07]),\n",
       " array([ 0.19,  0.18,  0.09,  0.24,  0.3 ]),\n",
       " array([ 0.06,  0.21,  0.15,  0.34,  0.24]),\n",
       " array([ 0.06,  0.21,  0.5 ,  0.23,  0.  ]),\n",
       " array([ 0.15,  0.18,  0.07,  0.12,  0.48]),\n",
       " array([ 0.13,  0.2 ,  0.18,  0.22,  0.27]),\n",
       " array([ 0.05,  0.25,  0.13,  0.38,  0.19]),\n",
       " array([ 0.16,  0.17,  0.15,  0.21,  0.31]),\n",
       " array([ 0.  ,  0.14,  0.17,  0.16,  0.22]),\n",
       " array([ 0.05,  0.14,  0.55,  0.18,  0.08]),\n",
       " array([ 0.15,  0.14,  0.1 ,  0.27,  0.34]),\n",
       " array([ 0.2 ,  0.19,  0.15,  0.25,  0.21]),\n",
       " array([ 0.19,  0.19,  0.24,  0.28,  0.1 ]),\n",
       " array([ 0.18,  0.29,  0.11,  0.11,  0.31]),\n",
       " array([ 0.09,  0.21,  0.16,  0.16,  0.38]),\n",
       " array([ 0.  ,  0.13,  0.16,  0.19,  0.24]),\n",
       " array([ 0.19,  0.33,  0.24,  0.13,  0.11]),\n",
       " array([ 0.  ,  0.21,  0.19,  0.21,  0.14]),\n",
       " array([ 0.  ,  0.17,  0.2 ,  0.15,  0.18]),\n",
       " array([ 0.  ,  0.11,  0.33,  0.17,  0.06]),\n",
       " array([ 0.  ,  0.25,  0.18,  0.09,  0.08]),\n",
       " array([ 0.16,  0.19,  0.16,  0.13,  0.36]),\n",
       " array([ 0.  ,  0.16,  0.11,  0.19,  0.13]),\n",
       " array([ 0.11,  0.17,  0.04,  0.11,  0.57]),\n",
       " array([ 0.14,  0.19,  0.12,  0.1 ,  0.45]),\n",
       " array([ 0.  ,  0.16,  0.16,  0.13,  0.07]),\n",
       " array([ 0.15,  0.19,  0.16,  0.09,  0.41]),\n",
       " array([ 0.  ,  0.21,  0.14,  0.13,  0.01]),\n",
       " array([ 0.2 ,  0.29,  0.11,  0.06,  0.34]),\n",
       " array([ 0.  ,  0.16,  0.09,  0.09,  0.04]),\n",
       " array([ 0.09,  0.15,  0.11,  0.18,  0.47]),\n",
       " array([ 0.  ,  0.2 ,  0.15,  0.06,  0.01]),\n",
       " array([ 0.23,  0.28,  0.14,  0.18,  0.17]),\n",
       " array([ 0.11,  0.26,  0.29,  0.31,  0.03]),\n",
       " array([ 0.  ,  0.12,  0.21,  0.14,  0.24]),\n",
       " array([ 0.19,  0.26,  0.2 ,  0.17,  0.18]),\n",
       " array([ 0.  ,  0.13,  0.12,  0.13,  0.27]),\n",
       " array([ 0.28,  0.31,  0.21,  0.15,  0.05]),\n",
       " array([ 0.13,  0.29,  0.26,  0.18,  0.14]),\n",
       " array([ 0.  ,  0.13,  0.23,  0.26,  0.06]),\n",
       " array([ 0.09,  0.22,  0.3 ,  0.14,  0.25]),\n",
       " array([ 0.  ,  0.16,  0.16,  0.23,  0.  ]),\n",
       " array([ 0.17,  0.16,  0.19,  0.29,  0.19]),\n",
       " array([ 0.2 ,  0.12,  0.31,  0.19,  0.18]),\n",
       " array([ 0.  ,  0.08,  0.16,  0.17,  0.13]),\n",
       " array([ 0.13,  0.21,  0.19,  0.36,  0.11]),\n",
       " array([ 0.  ,  0.17,  0.2 ,  0.13,  0.22]),\n",
       " array([ 0.07,  0.15,  0.2 ,  0.23,  0.35]),\n",
       " array([ 0.17,  0.24,  0.29,  0.13,  0.17]),\n",
       " array([ 0.  ,  0.19,  0.05,  0.23,  0.04]),\n",
       " array([ 0.08,  0.12,  0.2 ,  0.33,  0.27]),\n",
       " array([ 0.23,  0.21,  0.36,  0.17,  0.03]),\n",
       " array([ 0.06,  0.21,  0.15,  0.09,  0.49]),\n",
       " array([ 0.  ,  0.13,  0.25,  0.21,  0.08]),\n",
       " array([ 0.  ,  0.17,  0.16,  0.19,  0.24]),\n",
       " array([ 0.24,  0.27,  0.29,  0.14,  0.06]),\n",
       " array([ 0.    ,  0.2375,  0.1825,  0.19  ,  0.04  ]),\n",
       " array([ 0.16,  0.22,  0.21,  0.08,  0.33]),\n",
       " array([ 0.1 ,  0.16,  0.1 ,  0.14,  0.5 ]),\n",
       " array([ 0.05,  0.17,  0.51,  0.23,  0.04]),\n",
       " array([ 0.32,  0.33,  0.12,  0.13,  0.1 ]),\n",
       " array([ 0.  ,  0.09,  0.16,  0.11,  0.01]),\n",
       " array([ 0.1 ,  0.25,  0.29,  0.22,  0.14]),\n",
       " array([ 0.  ,  0.19,  0.15,  0.26,  0.07]),\n",
       " array([ 0.  ,  0.19,  0.2 ,  0.19,  0.08]),\n",
       " array([ 0.13,  0.2 ,  0.13,  0.08,  0.46]),\n",
       " array([ 0.18,  0.14,  0.35,  0.14,  0.19]),\n",
       " array([ 0.15,  0.19,  0.37,  0.28,  0.01])]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def condense_proba(p):\n",
    "    new_probas = []\n",
    "    for a in p:\n",
    "        cat = a[0] + a[1] + a[2]\n",
    "        new_probas.append([float(cat), float(a[3]), float(a[4])])\n",
    "    return new_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def condense_y(y_list):\n",
    "    new_list = []\n",
    "    for y in y_list:\n",
    "        if y == 1 or y == 2 or y == 3:\n",
    "            new_list.append(3)\n",
    "        else:\n",
    "            new_list.append(y)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condense_y(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "rfc = RFC(n_estimators = 100)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass_rate(gen_preds(condense_proba(rfc.predict_proba(X_train))), condense_y(list(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = rfc.predict_proba(X_train)\n",
    "p2 = condense_proba(p2)\n",
    "p2 = gen_preds(p2)\n",
    "y2 = condense_y(list(y_train))\n",
    "misclass_rate(p2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.963076923076923"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = rfc.predict_proba(X_test)\n",
    "p1 = condense_proba(p1)\n",
    "p1 = gen_preds(p1)\n",
    "y1 = condense_y(list(y_test))\n",
    "misclass_rate(p1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0],\n",
       "       [  0,   0,   0],\n",
       "       [259,   0,   0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(list(y2), p2,labels=[3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0],\n",
       "       [10,  0,  0],\n",
       "       [28,  0,  0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(list(y1), p1,labels=[3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.61, 0.21, 0.18]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_probas = []\n",
    "for item in p:\n",
    "    a = item\n",
    "    if list(item).index(max(item)) == 0:\n",
    "        a[0] = 0\n",
    "        new_probas.append(a)\n",
    "    else:\n",
    "        new_probas.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56, 12, 12,  5,  5],\n",
       "       [36, 12, 28,  6, 29],\n",
       "       [25, 11, 35, 14, 20],\n",
       "       [30, 15, 28, 22, 35],\n",
       "       [ 9,  5,  4,  4, 78]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(list(y_test),te_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def misclass_rate(pred, y):\n",
    "    incorr = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] != y[i]:\n",
    "            incorr += 1\n",
    "    return float(incorr)/float(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_preds(probas):\n",
    "    preds = []\n",
    "    for a in probas:\n",
    "        preds.append(a.index(max(a)) + 3)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-cda34f476822>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-125-0d7da9d7b8e3>\u001b[0m in \u001b[0;36mgen_preds\u001b[0;34m(probas)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprobas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "gen_preds(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
